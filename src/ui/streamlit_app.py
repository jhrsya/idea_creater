"""
Streamlitç”¨æˆ·ç•Œé¢
"""
import streamlit as st
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
from pathlib import Path
import json
from typing import List, Dict
import sys
import os

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(os.path.dirname(__file__))))

from config.settings import settings
from src.crawler.arxiv_crawler import ArXivCrawler
from src.parser.pdf_parser import PDFParser
from src.extractor.innovation_extractor import InnovationExtractor
from src.generator.idea_generator import IdeaGenerator


def main():
    """ä¸»åº”ç”¨å‡½æ•°"""
    st.set_page_config(
        page_title="æ™ºèƒ½è®ºæ–‡åˆ›æ–°ç‚¹ç”Ÿæˆå™¨",
        page_icon="ğŸ§ ",
        layout="wide",
        initial_sidebar_state="expanded"
    )
    
    st.title("ğŸ§  æ™ºèƒ½è®ºæ–‡åˆ›æ–°ç‚¹ç”Ÿæˆå™¨")
    st.markdown("åŸºäºArXivè®ºæ–‡åˆ†æï¼Œæå–åˆ›æ–°ç‚¹å¹¶ç”Ÿæˆæ–°çš„ç ”ç©¶æ–¹å‘")
    
    # ä¾§è¾¹æ 
    with st.sidebar:
        st.header("ğŸ“‹ åŠŸèƒ½å¯¼èˆª")
        page = st.selectbox(
            "é€‰æ‹©åŠŸèƒ½",
            ["è®ºæ–‡æœç´¢", "è®ºæ–‡è§£æ", "åˆ›æ–°ç‚¹æå–", "æƒ³æ³•ç”Ÿæˆ", "ç»“æœæŸ¥çœ‹"]
        )
        
        st.header("âš™ï¸ è®¾ç½®")
        max_papers = st.slider("æœ€å¤§è®ºæ–‡æ•°é‡", 5, 100, 20)
        use_ai = st.checkbox("ä½¿ç”¨AIæ¨¡å‹", value=True)
        
        if use_ai:
            ai_model = st.selectbox("AIæ¨¡å‹", ["OpenAI GPT-4", "Claude-3", "DeepSeek", "è‡ªåŠ¨é€‰æ‹©"])
            provider_map = {
                "OpenAI GPT-4": "openai",
                "Claude-3": "anthropic",
                "DeepSeek": "deepseek",
                "è‡ªåŠ¨é€‰æ‹©": settings.AI_PROVIDER
            }
            provider = provider_map[ai_model] if ai_model in provider_map else str(settings.AI_PROVIDER)
    
    # ä¸»å†…å®¹åŒºåŸŸ
    if page == "è®ºæ–‡æœç´¢":
        show_paper_search_page(max_papers)
    elif page == "è®ºæ–‡è§£æ":
        show_paper_parsing_page()
    elif page == "åˆ›æ–°ç‚¹æå–":
        show_innovation_extraction_page(use_ai, str(ai_model), provider)
    elif page == "æƒ³æ³•ç”Ÿæˆ":
        show_idea_generation_page(use_ai, str(ai_model), provider)
    elif page == "ç»“æœæŸ¥çœ‹":
        show_results_page()


def show_paper_search_page(max_papers: int):
    """è®ºæ–‡æœç´¢é¡µé¢"""
    st.header("ğŸ” è®ºæ–‡æœç´¢")
    
    col1, col2 = st.columns([2, 1])
    
    with col1:
        search_query = st.text_input(
            "æœç´¢æŸ¥è¯¢",
            placeholder="ä¾‹å¦‚ï¼šmachine learning, deep learning, transformer"
        )
        
        search_options = st.expander("é«˜çº§æœç´¢é€‰é¡¹")
        with search_options:
            col_a, col_b = st.columns(2)
            with col_a:
                category = st.selectbox(
                    "è®ºæ–‡ç±»åˆ«",
                    ["å…¨éƒ¨", "cs.AI", "cs.LG", "cs.CV", "cs.NLP", "cs.CL"]
                )
                sort_by = st.selectbox("æ’åºæ–¹å¼", ["æäº¤æ—¥æœŸ", "ç›¸å…³æ€§", "å¼•ç”¨æ¬¡æ•°"])
            
            with col_b:
                date_range = st.selectbox("æ—¶é—´èŒƒå›´", ["å…¨éƒ¨", "æœ€è¿‘ä¸€å‘¨", "æœ€è¿‘ä¸€æœˆ", "æœ€è¿‘ä¸‰æœˆ"])
                max_results = int(st.number_input("æœ€å¤§ç»“æœæ•°", min_value=1, max_value=max_papers, value=10))
    
    with col2:
        st.subheader("æœç´¢ç»Ÿè®¡")
        if st.button("ğŸ” å¼€å§‹æœç´¢", type="primary"):
            if search_query:
                with st.spinner("æ­£åœ¨æœç´¢è®ºæ–‡..."):
                    try:
                        crawler = ArXivCrawler()
                        
                        # æ„å»ºæœç´¢æŸ¥è¯¢
                        query = search_query
                        if category != "å…¨éƒ¨":
                            query += f" AND cat:{category}"
                        
                        papers = crawler.search_papers(query, max_results)
                        
                        if papers:
                            st.success(f"æ‰¾åˆ° {len(papers)} ç¯‡è®ºæ–‡")
                            
                            # æ˜¾ç¤ºè®ºæ–‡åˆ—è¡¨
                            st.subheader("ğŸ“„ æœç´¢ç»“æœ")
                            for i, paper in enumerate(papers, 1):
                                with st.expander(f"{i}. {paper.title}"):
                                    st.write(f"**ä½œè€…:** {', '.join(paper.authors)}")
                                    st.write(f"**æ‘˜è¦:** {paper.abstract[:300]}...")
                                    st.write(f"**ç±»åˆ«:** {', '.join(paper.categories)}")
                                    st.write(f"**å‘å¸ƒæ—¥æœŸ:** {paper.published_date.strftime('%Y-%m-%d')}")
                            
                            # ä¸‹è½½é€‰é¡¹
                            if st.button("ğŸ“¥ ä¸‹è½½è®ºæ–‡"):
                                with st.spinner("æ­£åœ¨ä¸‹è½½è®ºæ–‡..."):
                                    downloaded = crawler.download_papers(papers)
                                    st.success(f"æˆåŠŸä¸‹è½½ {len(downloaded)} ç¯‡è®ºæ–‡")
                        else:
                            st.warning("æœªæ‰¾åˆ°ç›¸å…³è®ºæ–‡")
                            
                    except Exception as e:
                        st.error(f"æœç´¢å¤±è´¥: {e}")
            else:
                st.warning("è¯·è¾“å…¥æœç´¢æŸ¥è¯¢")


def show_paper_parsing_page():
    """è®ºæ–‡è§£æé¡µé¢"""
    st.header("ğŸ“– è®ºæ–‡è§£æ")
    
    # æ£€æŸ¥æ˜¯å¦æœ‰PDFæ–‡ä»¶
    pdf_dir = settings.DATA_DIR / "papers"
    pdf_files = list(pdf_dir.glob("*.pdf")) if pdf_dir.exists() else []
    
    if not pdf_files:
        st.warning("æœªæ‰¾åˆ°PDFæ–‡ä»¶ï¼Œè¯·å…ˆä¸‹è½½è®ºæ–‡")
        return
    
    st.subheader(f"ğŸ“ å‘ç° {len(pdf_files)} ä¸ªPDFæ–‡ä»¶")
    
    # æ˜¾ç¤ºæ–‡ä»¶åˆ—è¡¨
    for pdf_file in pdf_files:
        st.write(f"ğŸ“„ {pdf_file.name}")
    
    if st.button("ğŸ” å¼€å§‹è§£æ", type="primary"):
        with st.spinner("æ­£åœ¨è§£æè®ºæ–‡..."):
            try:
                parser = PDFParser()
                output_dir = settings.DATA_DIR / "extracted"
                
                parsed_papers = parser.batch_parse_papers(pdf_dir, output_dir)
                
                if parsed_papers:
                    st.success(f"æˆåŠŸè§£æ {len(parsed_papers)} ç¯‡è®ºæ–‡")
                    
                    # æ˜¾ç¤ºè§£æç»“æœ
                    st.subheader("ğŸ“Š è§£æç»Ÿè®¡")
                    col1, col2, col3 = st.columns(3)
                    
                    with col1:
                        st.metric("æ€»è®ºæ–‡æ•°", len(parsed_papers))
                    
                    with col2:
                        total_sections = sum(len(paper.sections) for paper in parsed_papers)
                        st.metric("æ€»ç« èŠ‚æ•°", total_sections)
                    
                    with col3:
                        avg_sections = total_sections / len(parsed_papers) if parsed_papers else 0
                        st.metric("å¹³å‡ç« èŠ‚æ•°", f"{avg_sections:.1f}")
                    
                    # æ˜¾ç¤ºè§£æè¯¦æƒ…
                    st.subheader("ğŸ“‹ è§£æè¯¦æƒ…")
                    for paper in parsed_papers:
                        with st.expander(f"ğŸ“„ {paper.title}"):
                            st.write(f"**æ‘˜è¦:** {paper.abstract[:200]}...")
                            st.write(f"**ç« èŠ‚æ•°:** {len(paper.sections)}")
                            st.write(f"**å‚è€ƒæ–‡çŒ®æ•°:** {len(paper.references)}")
                            
                            if paper.sections:
                                st.write("**ç« èŠ‚åˆ—è¡¨:**")
                                for section in paper.sections[:5]:  # æ˜¾ç¤ºå‰5ä¸ªç« èŠ‚
                                    st.write(f"- {section.title}")
                else:
                    st.error("è§£æå¤±è´¥")
                    
            except Exception as e:
                st.error(f"è§£æå¤±è´¥: {e}")


def show_innovation_extraction_page(use_ai: bool, ai_model: str, provider: str):
    """åˆ›æ–°ç‚¹æå–é¡µé¢"""
    st.header("ğŸ’¡ åˆ›æ–°ç‚¹æå–")
    
    # æ£€æŸ¥æ˜¯å¦æœ‰è§£æåçš„è®ºæ–‡
    extracted_dir = settings.DATA_DIR / "extracted"
    json_files = list(extracted_dir.glob("*_parsed.json")) if extracted_dir.exists() else []
    
    if not json_files:
        st.warning("æœªæ‰¾åˆ°è§£æåçš„è®ºæ–‡ï¼Œè¯·å…ˆè§£æè®ºæ–‡")
        return
    
    st.subheader(f"ğŸ“ å‘ç° {len(json_files)} ä¸ªè§£ææ–‡ä»¶")
    
    if not use_ai:
        st.warning("AIåŠŸèƒ½å·²ç¦ç”¨ï¼Œæ— æ³•æå–åˆ›æ–°ç‚¹")
        return
    
    if st.button("ğŸ” å¼€å§‹æå–", type="primary"):
        with st.spinner("æ­£åœ¨æå–åˆ›æ–°ç‚¹..."):
            try:
                extractor = InnovationExtractor()
                
                # åŠ è½½è§£æåçš„è®ºæ–‡
                parsed_papers = []
                for json_file in json_files:
                    with open(json_file, 'r', encoding='utf-8') as f:
                        data = json.load(f)
                        # è¿™é‡Œéœ€è¦å°†JSONæ•°æ®è½¬æ¢ä¸ºParsedPaperå¯¹è±¡
                        # ç®€åŒ–å¤„ç†ï¼Œç›´æ¥ä½¿ç”¨æ–‡æœ¬å†…å®¹
                        parsed_papers.append({
                            'title': data.get('title', ''),
                            'full_text': data.get('full_text', '')
                        })
                
                # æå–åˆ›æ–°ç‚¹
                output_dir = settings.DATA_DIR / "innovations"
                extracted_innovations = []
                
                for paper in parsed_papers[:5]:  # é™åˆ¶å¤„ç†æ•°é‡
                    extracted = extractor.extract_innovations(
                        paper['full_text'], 
                        paper['title'],
                        use_model="auto"
                    )
                    if extracted:
                        extracted_innovations.append(extracted)
                
                if extracted_innovations:
                    st.success(f"æˆåŠŸæå– {len(extracted_innovations)} ç¯‡è®ºæ–‡çš„åˆ›æ–°ç‚¹")
                    
                    # æ˜¾ç¤ºæå–ç»“æœ
                    st.subheader("ğŸ“Š æå–ç»Ÿè®¡")
                    total_innovations = sum(len(ext.innovations) for ext in extracted_innovations)
                    st.metric("æ€»åˆ›æ–°ç‚¹æ•°", total_innovations)
                    
                    # æ˜¾ç¤ºåˆ›æ–°ç‚¹è¯¦æƒ…
                    st.subheader("ğŸ’¡ åˆ›æ–°ç‚¹è¯¦æƒ…")
                    for extracted in extracted_innovations:
                        with st.expander(f"ğŸ“„ {extracted.paper_title}"):
                            st.write(f"**åˆ›æ–°ç‚¹æ•°é‡:** {len(extracted.innovations)}")
                            st.write(f"**æ€»ç»“:** {extracted.summary[:200]}...")
                            
                            for i, innovation in enumerate(extracted.innovations, 1):
                                st.write(f"**åˆ›æ–°ç‚¹ {i}:** {innovation.title}")
                                st.write(f"æè¿°: {innovation.description[:150]}...")
                                st.write(f"ç±»åˆ«: {innovation.category}")
                                st.write(f"æ–°é¢–æ€§: {innovation.novelty_score:.2f}")
                                st.write("---")
                else:
                    st.error("æå–å¤±è´¥")
                    
            except Exception as e:
                st.error(f"æå–å¤±è´¥: {e}")


def show_idea_generation_page(use_ai: bool, ai_model: str, provider: str):
    """æƒ³æ³•ç”Ÿæˆé¡µé¢"""
    st.header("ğŸ’¡ æƒ³æ³•ç”Ÿæˆ")
    
    # æ£€æŸ¥æ˜¯å¦æœ‰æå–çš„åˆ›æ–°ç‚¹
    innovations_dir = settings.DATA_DIR / "innovations"
    innovation_files = list(innovations_dir.glob("*_innovations.json")) if innovations_dir.exists() else []
    
    if not innovation_files:
        st.warning("æœªæ‰¾åˆ°åˆ›æ–°ç‚¹æ–‡ä»¶ï¼Œè¯·å…ˆæå–åˆ›æ–°ç‚¹")
        return
    
    st.subheader(f"ğŸ“ å‘ç° {len(innovation_files)} ä¸ªåˆ›æ–°ç‚¹æ–‡ä»¶")
    
    topic = st.text_input("ç ”ç©¶ä¸»é¢˜", placeholder="ä¾‹å¦‚ï¼šæ·±åº¦å­¦ä¹ åœ¨è‡ªç„¶è¯­è¨€å¤„ç†ä¸­çš„åº”ç”¨")
    
    if st.button("ğŸš€ ç”Ÿæˆæƒ³æ³•", type="primary"):
        if not topic:
            st.warning("è¯·è¾“å…¥ç ”ç©¶ä¸»é¢˜")
            return
        
        with st.spinner("æ­£åœ¨ç”Ÿæˆæƒ³æ³•..."):
            try:
                generator = IdeaGenerator()
                
                # åŠ è½½åˆ›æ–°ç‚¹
                innovations_list = []
                for json_file in innovation_files:
                    with open(json_file, 'r', encoding='utf-8') as f:
                        data = json.load(f)
                        # è¿™é‡Œéœ€è¦å°†JSONæ•°æ®è½¬æ¢ä¸ºExtractedInnovationså¯¹è±¡
                        # ç®€åŒ–å¤„ç†
                        innovations_list.append(data)
                
                # ç”Ÿæˆæƒ³æ³•
                result = generator.generate_ideas_from_innovations(innovations_list, topic)
                
                if result:
                    st.success(f"æˆåŠŸç”Ÿæˆ {len(result.generated_ideas)} ä¸ªæ–°æƒ³æ³•")
                    
                    # æ˜¾ç¤ºç”Ÿæˆç»“æœ
                    st.subheader("ğŸ“Š ç”Ÿæˆç»Ÿè®¡")
                    col1, col2, col3 = st.columns(3)
                    
                    with col1:
                        st.metric("ç”Ÿæˆæƒ³æ³•æ•°", len(result.generated_ideas))
                    
                    with col2:
                        avg_novelty = sum(idea.novelty_score for idea in result.generated_ideas) / len(result.generated_ideas)
                        st.metric("å¹³å‡æ–°é¢–æ€§", f"{avg_novelty:.2f}")
                    
                    with col3:
                        avg_feasibility = sum(idea.feasibility_score for idea in result.generated_ideas) / len(result.generated_ideas)
                        st.metric("å¹³å‡å¯è¡Œæ€§", f"{avg_feasibility:.2f}")
                    
                    # æ˜¾ç¤ºæƒ³æ³•è¯¦æƒ…
                    st.subheader("ğŸ’¡ ç”Ÿæˆçš„æƒ³æ³•")
                    for i, idea in enumerate(result.generated_ideas, 1):
                        with st.expander(f"ğŸ’¡ {idea.title}"):
                            st.write(f"**æè¿°:** {idea.description}")
                            st.write(f"**æ¥æºåˆ›æ–°ç‚¹:** {', '.join(idea.source_innovations)}")
                            st.write(f"**ç»„åˆç±»å‹:** {idea.combination_type}")
                            st.write(f"**å¯è¡Œæ€§:** {idea.feasibility_score:.2f}")
                            st.write(f"**æ–°é¢–æ€§:** {idea.novelty_score:.2f}")
                            st.write(f"**æ½œåœ¨å½±å“:** {idea.impact_potential:.2f}")
                            st.write(f"**å®æ–½è·¯å¾„:** {idea.implementation_path}")
                            
                            if idea.research_directions:
                                st.write("**ç ”ç©¶æ–¹å‘:**")
                                for direction in idea.research_directions:
                                    st.write(f"- {direction}")
                    
                    # ä¿å­˜ç»“æœ
                    output_file = settings.DATA_DIR / "results" / f"{topic.replace(' ', '_')}_ideas.json"
                    generator.save_generation_result(result, output_file)
                    st.success(f"ç»“æœå·²ä¿å­˜åˆ°: {output_file}")
                else:
                    st.error("ç”Ÿæˆå¤±è´¥")
                    
            except Exception as e:
                st.error(f"ç”Ÿæˆå¤±è´¥: {e}")


def show_results_page():
    """ç»“æœæŸ¥çœ‹é¡µé¢"""
    st.header("ğŸ“Š ç»“æœæŸ¥çœ‹")
    
    # æ£€æŸ¥ç»“æœæ–‡ä»¶
    results_dir = settings.DATA_DIR / "results"
    result_files = list(results_dir.glob("*.json")) if results_dir.exists() else []
    
    if not result_files:
        st.warning("æœªæ‰¾åˆ°ç»“æœæ–‡ä»¶")
        return
    
    st.subheader(f"ğŸ“ å‘ç° {len(result_files)} ä¸ªç»“æœæ–‡ä»¶")
    
    # é€‰æ‹©è¦æŸ¥çœ‹çš„ç»“æœæ–‡ä»¶
    selected_file = st.selectbox("é€‰æ‹©ç»“æœæ–‡ä»¶", result_files)
    
    if selected_file and st.button("ğŸ“Š åŠ è½½ç»“æœ"):
        try:
            with open(selected_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            st.success(f"æˆåŠŸåŠ è½½ç»“æœ: {selected_file.name}")
            
            # æ˜¾ç¤ºåŸºæœ¬ä¿¡æ¯
            st.subheader("ğŸ“‹ åŸºæœ¬ä¿¡æ¯")
            col1, col2 = st.columns(2)
            
            with col1:
                st.write(f"**ç ”ç©¶ä¸»é¢˜:** {data.get('topic', 'N/A')}")
                st.write(f"**ç”Ÿæˆæƒ³æ³•æ•°:** {len(data.get('generated_ideas', []))}")
            
            with col2:
                metadata = data.get('generation_metadata', {})
                st.write(f"**æ€»åˆ›æ–°ç‚¹æ•°:** {metadata.get('total_innovations', 'N/A')}")
                st.write(f"**æ€»è®ºæ–‡æ•°:** {metadata.get('total_papers', 'N/A')}")
            
            # æ˜¾ç¤ºåˆ†ææ€»ç»“
            st.subheader("ğŸ“ˆ åˆ†ææ€»ç»“")
            st.text(data.get('analysis_summary', 'N/A'))
            
            # åˆ›å»ºå¯è§†åŒ–å›¾è¡¨
            st.subheader("ğŸ“Š å¯è§†åŒ–åˆ†æ")
            
            ideas = data.get('generated_ideas', [])
            if ideas:
                # åˆ›å»ºæ•°æ®æ¡†
                df = pd.DataFrame([
                    {
                        'title': idea['title'],
                        'novelty_score': idea['novelty_score'],
                        'feasibility_score': idea['feasibility_score'],
                        'impact_potential': idea['impact_potential'],
                        'combination_type': idea['combination_type']
                    }
                    for idea in ideas
                ])
                
                # æ•£ç‚¹å›¾ï¼šæ–°é¢–æ€§ vs å¯è¡Œæ€§
                fig1 = px.scatter(
                    df, x='novelty_score', y='feasibility_score',
                    title='åˆ›æ–°ç‚¹åˆ†å¸ƒï¼šæ–°é¢–æ€§ vs å¯è¡Œæ€§',
                    hover_data=['title']
                )
                st.plotly_chart(fig1, use_container_width=True)
                
                # æ¡å½¢å›¾ï¼šæŒ‰ç»„åˆç±»å‹ç»Ÿè®¡
                type_counts = df['combination_type'].value_counts()
                fig2 = px.bar(
                    x=type_counts.index, y=type_counts.values,
                    title='æƒ³æ³•ç±»å‹åˆ†å¸ƒ'
                )
                st.plotly_chart(fig2, use_container_width=True)
                
                # é›·è¾¾å›¾ï¼šå¹³å‡è¯„åˆ†
                avg_scores = {
                    'æ–°é¢–æ€§': df['novelty_score'].mean(),
                    'å¯è¡Œæ€§': df['feasibility_score'].mean(),
                    'æ½œåœ¨å½±å“': df['impact_potential'].mean()
                }
                
                fig3 = go.Figure()
                fig3.add_trace(go.Scatterpolar(
                    r=list(avg_scores.values()),
                    theta=list(avg_scores.keys()),
                    fill='toself',
                    name='å¹³å‡è¯„åˆ†'
                ))
                fig3.update_layout(
                    polar=dict(radialaxis=dict(visible=True, range=[0, 1])),
                    title='å¹³å‡è¯„åˆ†é›·è¾¾å›¾'
                )
                st.plotly_chart(fig3, use_container_width=True)
            
        except Exception as e:
            st.error(f"åŠ è½½ç»“æœå¤±è´¥: {e}")


if __name__ == "__main__":
    main() 